---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
df = read.csv('diabetes.csv')
df
summary(df) 
library(dplyr)
```

```{r}
cols_with_zeros = c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")

# Remplacer les zéros par NA dans ces colonnes
df = df %>%
  mutate(across(all_of(cols_with_zeros), ~na_if(., 0)))
df
colSums(is.na(df))



```

```{r}
for (col in cols_with_zeros) {
  median_value = median(df[[col]], na.rm = TRUE)
  df[[col]][is.na(df[[col]])] = median_value
}
df
colSums(is.na(df))
sapply(df[cols_with_zeros], function(x) sum(x == 0))


```



```{r}
library(dplyr)
library(ggplot2)
# Étape 1 : Créer BMICategory

df <- df %>%
  mutate(
    BMICategory = case_when(
      BMI < 18.5 ~ "Underweight",
      BMI >= 18.5 & BMI < 25 ~ "Normal",
      BMI >= 25 & BMI < 30 ~ "Overweight",
      BMI >= 30 ~ "Obese"
    )
  )
df
#verif rapide
table(df$BMICategory)

```



```{r}
# Étape 2 : Créer BPCategory

df <- df %>%
  mutate(
    BPCategory = case_when(
      BloodPressure < 80 ~ "Normal",
      BloodPressure >= 80 & BloodPressure < 90 ~ "Elevated",
      BloodPressure >= 90 ~ "High"
    )
  )
df

# Vérif rapide
table(df$BPCategory)


```


```{r}
# Étape 3 : Standardiser les colonnes numériques

numeric_cols <- names(df)[sapply(df, is.numeric)]
numeric_cols <- setdiff(numeric_cols, "Outcome")  # on ne touche pas à la cible

df_scaled <- df %>%
  mutate(across(all_of(numeric_cols), scale))

df_scaled
```


```{r}
# Étape 4 : Transformer Outcome en facteur lisible

df_scaled <- df_scaled %>%
  mutate(
    Outcome = factor(
      Outcome,
      levels = c(0, 1),
      labels = c("Not Diabetic", "Diabetic")
    )
  )
df_scaled



```



```{r}
#J’ai regroupé tout le code dans un seul bloc, car j’ai remarqué qu’après la standardisation, le programme utilisait les valeurs déjà standardisées pour calculer ou transformer certaines variables (notamment Outcome), ce qui entraînait l’apparition de valeurs manquantes (NA).
#En exécutant tout le code depuis le début dans un seul bloc, on s’assure que les données sont toujours traitées dans le bon ordre et à partir des valeurs d’origine, ce qui évite ces incohérences.

library(dplyr)

# 1️⃣ Recharger les données d'origine
df <- read.csv("diabetes.csv")

# 2️⃣ Nettoyer les zéros impossibles
cols_with_zeros <- c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")
df <- df %>%
  mutate(across(all_of(cols_with_zeros), ~na_if(., 0)))

for (col in cols_with_zeros) {
  median_value <- median(df[[col]], na.rm = TRUE)
  df[[col]][is.na(df[[col]])] <- median_value
}

# 3️⃣ Créer BMICategory
df <- df %>%
  mutate(
    BMICategory = case_when(
      BMI < 18.5 ~ "Underweight",
      BMI >= 18.5 & BMI < 25 ~ "Normal",
      BMI >= 25 & BMI < 30 ~ "Overweight",
      BMI >= 30 ~ "Obese"
    )
  )

# 4️⃣ Créer BPCategory
df <- df %>%
  mutate(
    BPCategory = case_when(
      BloodPressure < 80 ~ "Normal",
      BloodPressure >= 80 & BloodPressure < 90 ~ "Elevated",
      BloodPressure >= 90 ~ "High"
    )
  )

# 5️⃣ Standardiser les colonnes numériques
numeric_cols <- names(df)[sapply(df, is.numeric)]
numeric_cols <- setdiff(numeric_cols, "Outcome")

df_scaled <- df %>%
  mutate(across(all_of(numeric_cols), scale))

# 6️⃣ Transformer Outcome en facteur
df_scaled <- df_scaled %>%
  mutate(
    Outcome = factor(
      Outcome,
      levels = c(0, 1),
      labels = c("Not Diabetic", "Diabetic")
    )
  )
df_scaled

# 7️⃣ Vérifications
table(df_scaled$Outcome)
summary(df_scaled$BMICategory)
summary(df_scaled$BPCategory)

```



```{r}
 library(ggplot2)

# Recharger les données brutes pour comparaison
df_original <- read.csv("diabetes.csv")

ggplot() +
  geom_density(data = df_original, aes(x = Glucose),
               fill = "red", alpha = 0.4) +
  geom_density(data = df, aes(x = Glucose),
               fill = "green", alpha = 0.4) +
  labs(
    title = "Distribution du Glucose avant (rouge) et après nettoyage (vert)",
    x = "Taux de Glucose", y = "Densité"
  ) +
  theme_minimal()


```


```{r}
ggplot(df_scaled, aes(x = Glucose, fill = Outcome)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Distribution du Glucose selon l'état diabétique",
    x = "Glucose (standardisé)", y = "Densité"
  ) +
  theme_minimal()
### Glucose distribution by diabetes status

#The plot above compares glucose levels between diabetic and non-diabetic patients.  
#We can clearly observe that diabetic patients (in blue) tend to have higher glucose values,  
#while non-diabetic patients (in pink) are concentrated around lower values.  
#The small overlap between the two curves corresponds to borderline or pre-diabetic cases.  
#This visualization confirms that glucose is one of the most discriminating factors for detecting diabetes.

```


```{r}
# BMI
ggplot(df_scaled, aes(x = BMI, fill = Outcome)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Distribution du BMI selon l'état diabétique",
    x = "Indice de Masse Corporelle (standardisé)", y = "Densité"
  ) +
  theme_minimal()

# Âge
ggplot(df_scaled, aes(x = Age, fill = Outcome)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Distribution de l'âge selon l'état diabétique",
    x = "Âge (standardisé)", y = "Densité"
  ) +
  theme_minimal()

```


```{r}

library(GGally)

numeric_cols <- names(df_scaled)[sapply(df_scaled, is.numeric)]
corr_data <- df_scaled[, numeric_cols]

ggcorr(corr_data, label = TRUE, label_round = 2, hjust = 1, size = 3) +
  ggtitle("Matrice de corrélation entre les variables numériques")

### Correlation Matrix Analysis

#The correlation matrix highlights how numerical variables relate to each other.

#- The strongest positive correlation (0.54) is between *SkinThickness* and *BMI*, 
 # indicating that higher BMI values are associated with greater skinfold thickness.
#- *Glucose* and *Insulin* show a moderate positive correlation (0.42), 
 # which makes sense medically since high glucose levels often lead to increased insulin production.
#- *Pregnancies* and *Age* also correlate (0.54), 
  #as older women tend to have had more pregnancies.
#- Other variables show only weak correlations, 
 # suggesting that each feature provides distinct information for modeling.

#Overall, there is no sign of high multicollinearity between predictors, 
#meaning all features can be safely included in the modeling step.

```


```{r}
ggplot(df_scaled, aes(x = Age, y = DiabetesPedigreeFunction, color = Outcome)) +
  geom_point(alpha = 0.7, size = 3) +
  labs(
    title = "Lien entre l'âge et la fonction héréditaire du diabète",
    x = "Âge (standardisé)", y = "Diabetes Pedigree Function"
  ) +
  theme_minimal()

```


```{r}
ggplot(df_scaled, aes(x = BMICategory, y = BMI, fill = Outcome)) +
  geom_boxplot(alpha = 0.6) +
  labs(
    title = "Répartition du BMI par catégorie et par état diabétique",
    x = "Catégorie BMI", y = "BMI (standardisé)"
  ) +
  theme_minimal()

```


```{r}
ggplot(df_scaled, aes(x = BPCategory, fill = Outcome)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Répartition du diabète selon la catégorie de tension artérielle",
    x = "Catégorie de pression artérielle", y = "Nombre de patientes"
  ) +
  theme_minimal()

```

```{r}
# -----------------------------------------------
# STEP 4.1 : Préparation des données
# -----------------------------------------------
 
# On retire la colonne "Outcome" du jeu de données pour obtenir les variables explicatives X
X <- df_scaled %>% select(-Outcome)
 
# On garde la colonne Outcome (la variable à prédire : Diabetic / Not Diabetic)
y <- df_scaled$Outcome
 
# On crée un échantillon d'entraînement (80%) et un échantillon de test (20%)
# createDataPartition() sépare le jeu de données tout en gardant le même ratio
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
 
# Jeu d'entraînement (pour apprendre le modèle)
X_train <- X[train_index, ]
y_train <- y[train_index]
 
# Jeu de test (pour évaluer le modèle sur des données nouvelles)
X_test <- X[-train_index, ]
y_test <- y[-train_index]
```

```{r}
# -----------------------------------------------

# STEP 4.2 : Modèle 1 — Régression Logistique

# -----------------------------------------------
 
# On entraîne une régression logistique sur les données d'entraînement

# method = "glm" et family = "binomial" → modèle de régression logistique

model_log <- train(

  Outcome ~ ., 

  data = df_scaled[train_index, ],

  method = "glm",

  family = "binomial"

)
 
# On fait des prédictions sur le jeu de test

pred_log <- predict(model_log, newdata = df_scaled[-train_index, ])
 
# On évalue la performance du modèle avec une matrice de confusion

conf_log <- confusionMatrix(pred_log, y_test)
 
# On affiche les résultats

conf_log
 
```
```{r}
# -----------------------------------------------

# STEP 4.3 : Modèle 2 — K-Nearest Neighbors (KNN)

# -----------------------------------------------
 
# Le modèle KNN classe chaque patiente selon les K patientes les plus proches

model_knn <- train(

  Outcome ~ ., 

  data = df_scaled[train_index, ],

  method = "knn",

  tuneLength = 10   # test de plusieurs valeurs de K automatiquement

)
 
# Prédictions sur le jeu de test

pred_knn <- predict(model_knn, newdata = df_scaled[-train_index, ])
 
# Matrice de confusion pour évaluer les résultats

conf_knn <- confusionMatrix(pred_knn, y_test)
 
# Afficher les résultats

conf_knn

```
```{r}
# -----------------------------------------------
# STEP 4.4 : Comparaison des modèles
# -----------------------------------------------
 
# On rassemble les deux modèles pour les comparer
results <- resamples(list(Logistic = model_log, KNN = model_knn))
 
# Résumé des performances (accuracy, kappa, etc.)
summary(results)
 
# Visualisation sous forme de boxplot (pour comparer la stabilité)
bwplot(results, main = "Comparaison des modèles (Accuracy)")
```

```{r}
# -----------------------------------------------
# STEP 4.5 : Impact du nettoyage (avant vs après)
# -----------------------------------------------
 
# Charger les données originales (non nettoyées)
df_dirty <- read.csv("diabetes.csv")
 
# Convertir la variable Outcome en facteur (catégorielle)
df_dirty$Outcome <- factor(df_dirty$Outcome,
                           levels = c(0, 1),
                           labels = c("Not Diabetic", "Diabetic"))
 
# Entraîner une régression logistique sur les données brutes
model_dirty <- train(
  Outcome ~ ., 
  data = df_dirty,
  method = "glm", 
  family = "binomial"
)
 
# Faire des prédictions sur le même jeu
pred_dirty <- predict(model_dirty, newdata = df_dirty)
 
# Évaluer la performance du modèle non nettoyé
conf_dirty <- confusionMatrix(pred_dirty, df_dirty$Outcome)
 
# Afficher la matrice de confusion
conf_dirty

```
```{r}
# -----------------------------------------------
# STEP 4.6 : Résumé global des performances
# -----------------------------------------------
 
cat("=== Résumé des modèles ===\n")
cat("Régression Logistique (Nettoyée) → Accuracy :", round(conf_log$overall["Accuracy"], 3), "\n")
cat("KNN (Nettoyé) → Accuracy :", round(conf_knn$overall["Accuracy"], 3), "\n")
cat("Régression Logistique (Brute) → Accuracy :", round(conf_dirty$overall["Accuracy"], 3), "\n")
```

