---
title: "R Notebook"
output: html_notebook
---

# **PROJECT 4: Pima Diabetes - Detecting Diabetes from Imperfect Medical Data**

Project Goal : As data analysts in the healthcare sector, your team must build a model to predict the likelihood of diabetes in female patients of Pima Indian heritage. The primary challenge of this dataset is the presence of "impossible" data (zero values for biological measurements) that mask missing values. Your success will depend on your ability to identify and correct these anomalies before modeling.

```{r, include=FALSE}
# echo false pour toutes les cellules
knitr::opts_chunk$set(echo = FALSE) 

# Deleting previous environment
rm(list = ls())

# Importing needed libraries
library(dplyr)
library(ggplot2)
library(gridExtra)  # pour arranger les graphes
library(GGally)
library(caret)
```

## **Step 1: Data Cleaning and Preparation**

First, we import the data. Then we look at the beginning of the table to familiarize ourselves with it. And we create a summary to get an overview of the range of numerical values.

```{r}
df = read.csv('diabetes.csv')
head(df)
summary(df) 
```

We observe that certain values are 0. However, this does not always make sense in a medical context. We deduce that these values are missing. We will replace them with ‘NA’.

```{r}
cols_with_zeros = c("Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI")

# Remplacer les zéros par NA dans ces colonnes
df = df %>%
  mutate(across(all_of(cols_with_zeros), ~na_if(., 0)))

head(df)
```

The ‘NA’ value count:

```{r}
colSums(is.na(df))
```

In order to analyze our dataset, we need to fill in the ‘NA’ values. We choose to replace them with the median of their respective column.

```{r}
for (col in cols_with_zeros) {
  median_value = median(df[[col]], na.rm = TRUE)
  df[[col]][is.na(df[[col]])] = median_value
}

head(df)
```

All ‘NA’ values have been replaced & no more 0 remains:

```{r}
colSums(is.na(df))
cat("\n") # Ajout d'une ligne vide
sapply(df[cols_with_zeros], function(x) sum(x == 0))
```

## **Step 2: Feature Transformation and Engineering**

Before starting the analysis, we need to perform some transformations on our data.

### **Part 1: Creating BMI Categories**

Create a new categorical variable BMICategory from BMI using the World Health Organization's standard thresholds.

```{r}
#standard WHO thresholds: underweight, normal weight, overweight, obese
df <- df %>% 
  mutate(BMICategory = case_when(BMI<18.5 ~ 'Underweight', 
                                 BMI>=18.5 & BMI<25 ~ 'Normal weight', 
                                 BMI>=25 & BMI<30 ~ 'Overweight', BMI>=30 ~ 'Obese'),
         BMICategory = factor(BMICategory, levels = c('Underweight', 'Normal weight', 'Overweight',
                                                      'Obese')))
df %>% count(BMICategory)
```

### **Part 2: Creating Blood Pressure Categories**

Similarly, we create a BPCategory variable from BloodPressure

```{r}
#blood pressure categories: low, normal, elevated, high 
df <- df %>% 
  mutate(BPCategory = case_when(BloodPressure < 60 ~ "Low", 
                                BloodPressure >= 60 & BloodPressure < 80 ~ "Normal",
                                BloodPressure >= 80 & BloodPressure < 90 ~ "Elevated", 
                                BloodPressure >= 90 ~ "High"),
         BPCategory = factor(BPCategory, levels = c("Low", "Normal", "Elevated", "High")))

df %>% count(BPCategory)
```

### **Part 3: Target Transformation**

Now, we ensure the target variable Outcome is a factor with clear labels (e.g., "Diabetic", "Not Diabetic") for interpretability.

```{r}
df <- df %>% mutate(OutcomeLabel = case_when(Outcome==0 ~ 'Not Diabetic', 
                                                 Outcome==1 ~ 'Diabetic'),
                    OutcomeLabel = factor(OutcomeLabel, levels = c("Not Diabetic", "Diabetic")))
df %>% count(OutcomeLabel)
```

### **Part 4: Standardizing Variables**

Center and scale all numeric columns so their mean becomes 0 and their standard deviation becomes 1.

```{r}
numeric_cols <- names(df)[sapply(df, is.numeric)]
numeric_cols <- setdiff(numeric_cols, "Outcome")  # on ne touche pas à la cible

df_scaled <- df %>%
  mutate(across(all_of(numeric_cols), scale))

head(df_scaled)
```

## **Step 3: Visualization and Exploration (with ggplot2)**

blablabla

```{r}
# Recharger les données brutes pour comparaison
df_original <- read.csv("diabetes.csv")

# Graphe avant nettoyage
p1 <- ggplot(df_original, aes(x = Glucose)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Avant nettoyage", x = "Taux de Glucose", y = "Densité") +
  theme_minimal()
 
# Graphe après nettoyage
p2 <- ggplot(df_scaled, aes(x = Glucose)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(title = "Après nettoyage", x = "Taux de Glucose", y = "Densité") +
  theme_minimal()
 
# Afficher les deux côte à côte
grid.arrange(p1, p2, ncol = 2)
```

### **Part 1: Comparing Distributions**

```{r}
#distribution of BMI and age between diabetic and non-diabetic patients 

plot_bmi <- ggplot(df_scaled, aes(x=BMI, fill=OutcomeLabel)) + labs(title = 'BMI distribution', x='BMI', fill='Outcome') + geom_density(alpha = 0.5) 
  
plot_age <- ggplot(df_scaled, aes(x=Age, fill=OutcomeLabel)) + labs(title = 'Age distribution', x='Age', fill='Outcome') + geom_density(alpha = 0.5)

plot_bmi
plot_age
```

### **Part 2: Correlation Between Predictors**

jebcebzopeizfhpiez

```{r}
numeric_cols <- names(df_scaled)[sapply(df_scaled, is.numeric)]
corr_data <- df_scaled[, numeric_cols]

ggcorr(corr_data, label = TRUE, label_round = 2, hjust = 1, size = 3) +
  coord_cartesian(clip = "off") +                       # ← permet d’afficher hors panel
  ggtitle("Matrice de corrélation entre les variables numériques") +
  theme(plot.margin = margin(20, 100, 20, 100)) # augmente les marges (top, right, bottom, left
```

### **Part 3: Analyzing Pedigree**

```{r}
ggplot(df_scaled, aes(x = Age, y = DiabetesPedigreeFunction, color = OutcomeLabel)) +
  geom_point(alpha = 0.7, size = 3) +
  labs(
    title = "Lien entre l'âge et la fonction héréditaire du diabète",
    x = "Âge (standardisé)", y = "Diabetes Pedigree Function") 
```

### **Part 4: Visualisations of our choice**

rgrgregregreg

```{r}
plot_glucose <- ggplot(df_scaled, aes(x=Glucose, fill=OutcomeLabel)) + labs(title = 'Glucose distribution', x='glucose', fill='Outcome') + geom_density(alpha = 0.5) 
plot_glucose
```

```{r}
ggplot(df_scaled, aes(x = BloodPressure, y = Age , color = OutcomeLabel)) +
  geom_point(alpha = 0.7, size = 3)
```

## **Step 4:  Modeling and Prediction (Data Science)**

gregrerer

```{r}
set.seed(123)
train_index <- sample(1:nrow(df_scaled), 0.8 * nrow(df_scaled))
train_data <- df_scaled[train_index, ]
test_data <- df_scaled[-train_index, ]

model <- glm(Outcome ~ Glucose + BMI + Age + DiabetesPedigreeFunction + Pregnancies + BloodPressure + SkinThickness, data = train_data, family = binomial)

test_data$PredictedProb <- predict(model, newdata = test_data, type = "response")
test_data$PredictedClass <- ifelse(test_data$PredictedProb > 0.5, 1, 0)

confusion_matrix <- table(Predicted = test_data$PredictedClass, Actual = test_data$Outcome)
accuracy <- mean(test_data$PredictedClass == test_data$Outcome)

confusion_matrix
```




